{"cells":[{"cell_type":"markdown","metadata":{"id":"vncDsAP0Gaoa"},"source":["# **Customer_Churn_prediction**    -\n","\n"]},{"cell_type":"markdown","metadata":{"id":"beRrZCGUAJYm"},"source":["##### **Project Type**    - Churn Prediction - Supervised Classification - AUC-ROC\n","##### **Contribution**    - Individual"]},{"cell_type":"markdown","metadata":{"id":"FJNUwmbgGyua"},"source":["# **Project Summary -**"]},{"cell_type":"markdown","metadata":{"id":"F6v_1wHtG2nS"},"source":["The following data used for this project is of a credit card churn prediction dataset.\n","\n","Customer churn prediction is extremely important for any business as it recognizes the clients who are likely to stop using their services\n","\n","In banking sector or for credit card Industries, Customer are able to migrate from one to another. So it is important to estimate the posible churn rate of customer for better knowladge of the possible migration of the customer.\n","\n","**Lets Start !**"]},{"cell_type":"markdown","metadata":{"id":"yQaldy8SH6Dl"},"source":["# **Problem Statement**\n"]},{"cell_type":"markdown","metadata":{"id":"DpeJGUA3kjGy"},"source":["**Here we will identify whether a customer leave or migrate to another bank or close the account.**"]},{"cell_type":"markdown","metadata":{"id":"mDgbUHAGgjLW"},"source":["# **General Guidelines** : -  "]},{"cell_type":"markdown","metadata":{"id":"ZrxVaUj-hHfC"},"source":["1.   Well-structured, formatted, and commented code is required.\n","2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n","     \n","     The additional credits will have advantages over other students during Star Student selection.\n","       \n","             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n","                       without a single error logged. ]\n","\n","3.   Each and every logic should have proper comments.\n","4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n","        \n","\n","```\n","# Chart visualization code\n","```\n","            \n","\n","*   Why did you pick the specific chart?\n","*   What is/are the insight(s) found from the chart?\n","* Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n","5. You have to create at least 15 logical & meaningful charts having important insights.\n","\n","\n","[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n","\n","U - Univariate Analysis,\n","\n","B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n","\n","M - Multivariate Analysis\n"," ]\n","\n","\n","\n","\n","\n","6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n","\n","\n","*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n","\n","\n","*   Cross- Validation & Hyperparameter Tuning\n","\n","*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n","\n","*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"O_i_v8NEhb9l"},"source":["# ***Let's Begin !***"]},{"cell_type":"markdown","metadata":{"id":"HhfV-JJviCcP"},"source":["## ***1. Know Your Data***"]},{"cell_type":"markdown","metadata":{"id":"Y3lxredqlCYt"},"source":["### Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M8Vqi-pPk-HR"},"outputs":[],"source":["# Import Libraries\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","from matplotlib import pyplot as plt\n","\n","import tensorflow\n","from tensorflow import keras\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","from scipy.stats import *\n","import math"]},{"cell_type":"markdown","metadata":{"id":"3RnN4peoiCZX"},"source":["### Dataset Loading"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"wGdnJQ7okYGn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4CkvbW_SlZ_R"},"outputs":[],"source":["# Load Dataset\n","df = pd.read_csv('/content/drive/MyDrive/AlmabetterProjects/Machine learning/MidTermProject/Churn_Modelling.csv')"]},{"cell_type":"markdown","metadata":{"id":"x71ZqKXriCWQ"},"source":["### Dataset First View"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LWNFOSvLl09H"},"outputs":[],"source":["# Dataset First Look\n","df.head(10)"]},{"cell_type":"markdown","metadata":{"id":"-dRFGfnhkFwd"},"source":["**since there is no need of Customerld and Surname column here so this must be droped.**"]},{"cell_type":"markdown","metadata":{"id":"7hBIi_osiCS2"},"source":["### Dataset Rows & Columns count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kllu7SJgmLij"},"outputs":[],"source":["# Dataset Rows & Columns count\n","df.shape"]},{"cell_type":"markdown","metadata":{"id":"xUej9iBTkFwf"},"source":["We have 10000 rows and 14 columns in here."]},{"cell_type":"markdown","metadata":{"id":"JlHwYmJAmNHm"},"source":["### Dataset Information"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e9hRXRi6meOf"},"outputs":[],"source":["# Dataset Info\n","df.info()"]},{"cell_type":"markdown","metadata":{"id":"HQyTiJQ0kFwg"},"source":["As we can see in this data there is no null value so we will procede. Here we have 2 float values 9 integer values and 3 obeject\n","Column in this dataset."]},{"cell_type":"markdown","metadata":{"id":"35m5QtbWiB9F"},"source":["#### Duplicate Values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1sLdpKYkmox0"},"outputs":[],"source":["# Dataset Duplicate Value Count\n","df.duplicated().sum()"]},{"cell_type":"markdown","metadata":{"id":"iukmSan9kFwh"},"source":["In this dataset there is no such type of duplicate value."]},{"cell_type":"markdown","metadata":{"id":"PoPl-ycgm1ru"},"source":["#### Missing Values/Null Values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GgHWkxvamxVg"},"outputs":[],"source":["# Missing Values/Null Values Count\n","df.isnull().sum()"]},{"cell_type":"markdown","metadata":{"id":"3q5wnI3om9sJ"},"source":["There is no null values or missing values present in the data."]},{"cell_type":"markdown","metadata":{"id":"H0kj-8xxnORC"},"source":["### What did you know about your dataset?"]},{"cell_type":"markdown","metadata":{"id":"gfoNAAC-nUe_"},"source":["since there is no need of Customerld and Surname column here so this must be droped. We have 10000 rows and 14 columns in here. As we can see in this data there is no null value so we will procede. Here we have 2 float values 9 integer values and 3 obeject Column in this dataset.\n","\n","In this dataset there is no such type of duplicate value. There is no null values or missing values present in the data. This data is mainly from three contries **France**, **Spain**, and **Germany**."]},{"cell_type":"markdown","metadata":{"id":"nA9Y7ga8ng1Z"},"source":["## ***2. Understanding Your Variables***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j7xfkqrt5Ag5"},"outputs":[],"source":["# Dataset Columns\n","df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DnOaZdaE5Q5t"},"outputs":[],"source":["# Dataset Describe\n","df.describe()"]},{"cell_type":"markdown","metadata":{"id":"PBTbrJXOngz2"},"source":["### Variables Description"]},{"cell_type":"markdown","metadata":{"id":"Sx0GzwLZkFwm"},"source":["* **RowNumber :-** Simple Row count.\n","* **CustomerId :-** unique id of the customer.\n","* **surname :-** surname used by the customer.\n","* **CreditScore :-** Credit card score of the customer.\n","* **Geography :-** Location of the customer.\n","* **Gender :-** Gender of the customer.\n","* **Age :-** Age of the Customer\n","* **Tenure :-** Tenure from how many years the customer is with bank.\n","* **Balance :-** Balance of the customer.\n","* **NumOfProducts :-** Number of products Fd etc of customer\n","* **HasCrCard :-** mainly 0 if has credit card and 1 if not.\n","* **IsActiveMember :-** 0 if active member 1 if left.\n","* **EstimatedSalary :-** estimated salary of the customer.\n","* **Exited :-** 0 if present customer the bank 1 if left membership."]},{"cell_type":"markdown","metadata":{"id":"u3PMJOP6ngxN"},"source":["### Check Unique Values for each variable."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zms12Yq5n-jE"},"outputs":[],"source":["# Check Unique Values for each variable.\n","for i in df.columns.tolist():\n","  print(\"No. of unique values in \",i,\"is\",df[i].nunique(),\".\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L_K7uzkokFwn"},"outputs":[],"source":["# droping the columns which are of no use.\n","df.drop(columns = ['RowNumber','CustomerId','Surname'],inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rXhd5935kFws"},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"id":"dauF4eBmngu3"},"source":["## 3. ***Data Wrangling***"]},{"cell_type":"markdown","metadata":{"id":"bKJF3rekwFvQ"},"source":["### Data Wrangling Code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wk-9a2fpoLcV"},"outputs":[],"source":["# Write your code to make your dataset analysis ready.\n","# Create a copy of the current dataset and assigning to df\n","new_df=df.copy()\n","# Checking Shape of True Value\n","print(\"No. of customers Churning : -\",len(new_df[new_df['Exited']==1]))\n","# Assigning churn customers data to variable df_churn\n","df_churn=new_df[(new_df['Exited']==1)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XbG-x_MFkFwt"},"outputs":[],"source":["# Churn data groupby Country Wise\n","C_churn=pd.DataFrame(df.groupby('Geography')['Exited'].value_counts().reset_index(name=\"Count\"))\n","C_churn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UlJN8QvVkFwt"},"outputs":[],"source":["# Visualisation\n","sns.barplot(x='Geography',y='Count',data=C_churn,hue='Exited')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ytv1xWZ-kFwt"},"outputs":[],"source":["# Churn data groupby Gender Wise\n","G_churn=pd.DataFrame(df.groupby('Gender')['Exited'].value_counts().reset_index(name=\"Count\"))\n","G_churn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7V_geZ79kFwu"},"outputs":[],"source":["sns.barplot(x='Gender',y='Count',data=G_churn,hue='Exited')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"acvaruZKkFwu"},"outputs":[],"source":["# Function to get all area code mean & median while passing area code and dataframe.\n","def get_mean_median(df,area):\n","  '''\n","  This function returns the mean and median of the whole dataset for a particular area.\n","\n","  '''\n","  try:\n","    return pd.concat([df[(df['Exited']==1)&(df['Geography']==area)].describe().iloc[1],\n","            df[(df['Exited']==1)&(df['Geography']==area)].describe().iloc[5]],\n","            axis=1).rename(columns={\"50%\":\"median\"}).fillna(\"-\")\n","  except:\n","    print(\"Invalid Geography\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lIhtLN5WkFwu"},"outputs":[],"source":["# Getting Mean Median for Geography France\n","get_mean_median(df=new_df,area='France')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7AIG621tkFwu"},"outputs":[],"source":["# Getting Mean Median for Geography Germany\n","get_mean_median(df=new_df,area='Germany')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u6VINLEfkFwv"},"outputs":[],"source":["# Getting Mean Median for Geography Spain\n","get_mean_median(df=new_df,area='Spain')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w90u_SgTkFwv"},"outputs":[],"source":["# Function to get all Gender mean & median while passing Gender and dataframe.\n","def get_mean_median_genderWise(df,area):\n","  '''\n","  This function returns the mean and median of the whole dataset for a particular area.\n","\n","  '''\n","  try:\n","    return pd.concat([df[(df['Exited']==1)&(df['Gender']==area)].describe().iloc[1],\n","            df[(df['Exited']==1)&(df['Gender']==area)].describe().iloc[5]],\n","            axis=1).rename(columns={\"50%\":\"median\"}).fillna(\"-\")\n","  except:\n","    print(\"Invalid Gender\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-CM_6bozkFwv"},"outputs":[],"source":["# Getting Mean Median for Gender male\n","get_mean_median_genderWise(df=new_df,area='Male')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zG5cZSTikFwv"},"outputs":[],"source":["# Getting Mean Median for Gender fmale\n","get_mean_median_genderWise(df=new_df,area='Female')"]},{"cell_type":"markdown","metadata":{"id":"v3Z3mJdkkFww"},"source":["## Identifying outliers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vHmR8MTDkFww"},"outputs":[],"source":["# Handling Outliers & Outlier treatments\n","# To separate the symmetric distributed features and skew symmetric distributed features\n","new_df[\"Geography\"]=new_df[\"Geography\"].astype('str')\n","symmetric_feature=[]\n","non_symmetric_feature=[]\n","for i in new_df.describe().columns:\n","  if abs(new_df[i].mean()-new_df[i].median())<0.2:\n","    symmetric_feature.append(i)\n","  else:\n","    non_symmetric_feature.append(i)\n","\n","# Getting Symmetric Distributed Features\n","print(\"Symmetric Distributed Features : -\",symmetric_feature)\n","\n","# Getting Skew Symmetric Distributed Features\n","print(\"Skew Symmetric Distributed Features : -\",non_symmetric_feature)\n","\n","# Removing Customer Service Calls column from the list as it's an important factor\n","# which can't be treated as outliers here will is already leading to higher churn as we have seen furing analysis.\n","non_symmetric_feature.pop()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wegSysyYkFww"},"outputs":[],"source":["# For Symmetric features defining upper and lower boundry\n","def outlier_treatment(df,feature):\n","  upper_boundary= df[feature].mean()+3*df[feature].std()\n","  lower_boundary= df[feature].mean()-3*df[feature].std()\n","  return upper_boundary,lower_boundary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"098dUNuIkFww"},"outputs":[],"source":["df=new_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OSVOS9HokFwx"},"outputs":[],"source":["# Restricting the data to lower and upper boundry\n","for feature in symmetric_feature:\n","  df.loc[df[feature]<= outlier_treatment(df=df,feature=feature)[1], feature]=outlier_treatment(df=df,feature=feature)[1]\n","  df.loc[df[feature]>= outlier_treatment(df=df,feature=feature)[0], feature]=outlier_treatment(df=df,feature=feature)[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1KlKF99xkFwx"},"outputs":[],"source":["# For Skew Symmetric features defining upper and lower boundry\n","#Outer Fence\n","def outlier_treatment_skew(df,feature):\n","  IQR= df[feature].quantile(0.75)- df[feature].quantile(0.25)\n","  lower_bridge =df[feature].quantile(0.25)-3*IQR\n","  upper_bridge =df[feature].quantile(0.25)+3*IQR\n","  return upper_bridge,lower_bridge"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qE2j3FOikFwx"},"outputs":[],"source":["for feature in non_symmetric_feature:\n","  df.loc[df[feature]<= outlier_treatment_skew(df=df,feature=feature)[1], feature]=outlier_treatment_skew(df=df,feature=feature)[1]\n","  df.loc[df[feature]>= outlier_treatment_skew(df=df,feature=feature)[0], feature]=outlier_treatment_skew(df=df,feature=feature)[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BA2X8nPMkFwy"},"outputs":[],"source":["# After Outlier Treatment showing the dataset distribution using strip plot\n","# Visualising  code for the numerical columns\n","for col in df.describe().columns:\n","  fig=plt.figure(figsize=(9,6))\n","  sns.stripplot(df[col])"]},{"cell_type":"markdown","metadata":{"id":"GgU_sgwAkFwy"},"source":["## Preparing ML modal"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bew-HwvZkFwy"},"outputs":[],"source":["new_df=df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eP1lQfgmkFwy"},"outputs":[],"source":["new_df = pd.get_dummies(new_df,columns=['Geography','Gender'],drop_first=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PqMYBqbQkFwz"},"outputs":[],"source":["new_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tshm5-R3kFwz"},"outputs":[],"source":["X = new_df.drop(columns=['Exited'])\n","y = new_df['Exited'].values\n","\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ao27_L-IkFwz"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","\n","X_train_trf = scaler.fit_transform(X_train)\n","X_test_trf = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nkph_v87kFw0"},"outputs":[],"source":["model = Sequential()\n","\n","model.add(Dense(11,activation='sigmoid',input_dim=11))\n","model.add(Dense(11,activation='sigmoid'))\n","model.add(Dense(1,activation='sigmoid'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aR1WHqcAkFw0"},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mbOyvUozkFw0"},"outputs":[],"source":["model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"0_NPsVA1kFw0"},"outputs":[],"source":["history = model.fit(X_train,y_train,batch_size=50,epochs=100,verbose=1,validation_split=0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ie-pEW6pkFw1"},"outputs":[],"source":["y_pred = model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JQzUgt__kFw1"},"outputs":[],"source":["y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6hZgo_k3kFw1"},"outputs":[],"source":["y_pred = y_pred.argmax(axis=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c-GMtMD5kFw2"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","accuracy_score(y_test,y_pred)"]},{"cell_type":"markdown","metadata":{"id":"hEHcbooMkFw2"},"source":["## We have a modal accuracy of 79.75"]},{"cell_type":"markdown","metadata":{"id":"-Kee-DAl2viO"},"source":["### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"]},{"cell_type":"markdown","metadata":{"id":"gCX9965dhzqZ"},"source":["# **Conclusion**"]},{"cell_type":"markdown","metadata":{"id":"Fjb1IsQkh3yE"},"source":["Write the conclusion here."]},{"cell_type":"markdown","metadata":{"id":"gIfDvo9L0UH2"},"source":["### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"]}],"metadata":{"colab":{"collapsed_sections":["-Kee-DAl2viO","gIfDvo9L0UH2"],"private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"}},"nbformat":4,"nbformat_minor":0}